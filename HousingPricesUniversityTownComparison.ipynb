{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 4 - Hypothesis Testing\n",
    "This assignment requires more individual learning than previous assignments - you are encouraged to check out the pandas documentation to find functions or methods you might not have used yet, or ask questions on Stack Overflow and tag them as pandas and python related. And of course, the discussion forums are open for interaction with your peers and the course staff.\n",
    "\n",
    "Definitions:\n",
    "\n",
    "A quarter is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
    "A recession is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "A recession bottom is the quarter within a recession which had the lowest GDP.\n",
    "A university town is a city which has a high percentage of university students compared to the total population of the city.\n",
    "Hypothesis: University towns have their mean housing prices less effected by recessions. Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom. (price_ratio=quarter_before_recession/recession_bottom)\n",
    "\n",
    "The following data files are available for this assignment:\n",
    "\n",
    "From the Zillow research data site there is housing data for the United States. In particular the datafile for all homes at a city level, City_Zhvi_AllHomes.csv, has median home sale prices at a fine grained level.\n",
    "From the Wikipedia page on college towns is a list of university towns in the United States which has been copy and pasted into the file university_towns.txt.\n",
    "From Bureau of Economic Analysis, US Department of Commerce, the GDP over time of the United States in current dollars (use the chained value in 2009 dollars), in quarterly intervals, in the file gdplev.xls. For this assignment, only look at GDP data from the first quarter of 2000 onward.\n",
    "Each function in this assignment below is worth 10%, with the exception of run_ttest(), which is worth 50%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary to map state names to two letter acronyms\n",
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_allhomes_df  = pd.read_csv(r'C:\\Users\\sjtal\\Documents\\python_datascience\\City_Zhvi_AllHomes.csv')\n",
    "zillow_allhomes_df.head()\n",
    "\n",
    "zillow_allhomes_df.loc[:, 'State'] = zillow_allhomes_df.loc[:, 'State'].map(states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Auburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Florence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jacksonville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Livingston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montevallo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>River Falls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Stevens Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Waukesha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Whitewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Laramie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         State     RegionName\n",
       "0      Alabama         Auburn\n",
       "1      Alabama       Florence\n",
       "2      Alabama   Jacksonville\n",
       "3      Alabama     Livingston\n",
       "4      Alabama     Montevallo\n",
       "..         ...            ...\n",
       "508  Wisconsin    River Falls\n",
       "509  Wisconsin  Stevens Point\n",
       "510  Wisconsin       Waukesha\n",
       "511  Wisconsin     Whitewater\n",
       "512    Wyoming        Laramie\n",
       "\n",
       "[513 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_list_of_university_towns():\n",
    "    '''Returns a DataFrame of towns and the states they are in from the \n",
    "    university_towns.txt list. The format of the DataFrame should be:\n",
    "    DataFrame( [ [\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Yipsilanti\"] ], \n",
    "    columns=[\"State\", \"RegionName\"]  )\n",
    "    \n",
    "    The following cleaning needs to be done:\n",
    "\n",
    "    1. For \"State\", removing characters from \"[\" to the end.\n",
    "    2. For \"RegionName\", when applicable, removing every character from \" (\" to the end.\n",
    "    3. Depending on how you read the data, you may need to remove newline character '\\n'. '''\n",
    "    \n",
    "    \n",
    "    state_town_tuple_list = []\n",
    "    with open(r'C:\\Users\\sjtal\\Documents\\python_datascience\\university_towns.txt') as fref:\n",
    "        for line in fref:\n",
    "            lineWithoutSquare = line.split('[')[0].strip()\n",
    "            if ':' in lineWithoutSquare and not ('(')  in lineWithoutSquare :\n",
    "                continue\n",
    "            else:\n",
    "                if not ('(')  in lineWithoutSquare:\n",
    "                    state = lineWithoutSquare\n",
    "                else:\n",
    "                    univTown = lineWithoutSquare.split(' (')[0].strip().split(',')[0].strip()\n",
    "                    state_town_tuple_list.append((state, univTown) )\n",
    "                \n",
    "        state_univtown_df = pd.DataFrame(state_town_tuple_list, columns =['State', 'RegionName'])\n",
    "    \n",
    "    return state_univtown_df\n",
    "\n",
    "get_list_of_university_towns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearQuarters</th>\n",
       "      <th>GDP(in Billions)</th>\n",
       "      <th>GDP(in Billions of chained 2009)</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2000q1</td>\n",
       "      <td>10031.0</td>\n",
       "      <td>12359.1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2000q2</td>\n",
       "      <td>10278.3</td>\n",
       "      <td>12592.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2000q3</td>\n",
       "      <td>10357.4</td>\n",
       "      <td>12607.7</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2000q4</td>\n",
       "      <td>10472.3</td>\n",
       "      <td>12679.3</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2001q1</td>\n",
       "      <td>10508.1</td>\n",
       "      <td>12643.3</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2015q2</td>\n",
       "      <td>17998.3</td>\n",
       "      <td>16374.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2015q3</td>\n",
       "      <td>18141.9</td>\n",
       "      <td>16454.9</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2015q4</td>\n",
       "      <td>18222.8</td>\n",
       "      <td>16490.7</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2016q1</td>\n",
       "      <td>18281.6</td>\n",
       "      <td>16525.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2016q2</td>\n",
       "      <td>18450.1</td>\n",
       "      <td>16583.1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    YearQuarters  GDP(in Billions)  GDP(in Billions of chained 2009)  \\\n",
       "214       2000q1           10031.0                           12359.1   \n",
       "215       2000q2           10278.3                           12592.5   \n",
       "216       2000q3           10357.4                           12607.7   \n",
       "217       2000q4           10472.3                           12679.3   \n",
       "218       2001q1           10508.1                           12643.3   \n",
       "..           ...               ...                               ...   \n",
       "275       2015q2           17998.3                           16374.2   \n",
       "276       2015q3           18141.9                           16454.9   \n",
       "277       2015q4           18222.8                           16490.7   \n",
       "278       2016q1           18281.6                           16525.0   \n",
       "279       2016q2           18450.1                           16583.1   \n",
       "\n",
       "    Unnamed: 10  \n",
       "214          No  \n",
       "215          No  \n",
       "216          No  \n",
       "217          No  \n",
       "218         Yes  \n",
       "..          ...  \n",
       "275          No  \n",
       "276          No  \n",
       "277          No  \n",
       "278          No  \n",
       "279          No  \n",
       "\n",
       "[66 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP_qtr = pd.read_excel(r'C:\\Users\\sjtal\\Documents\\python_datascience\\gdplev.xls', skiprows= 5)\n",
    "GDP_qtr= GDP_qtr.dropna(axis=0,how='all').dropna(axis=1,how='all').iloc[:,3:]\n",
    "GDP_qtr.rename(columns={GDP_qtr.columns[0]: \"YearQuarters\",\n",
    "                        GDP_qtr.columns[1]: \"GDP(in Billions)\",\n",
    "                        GDP_qtr.columns[2]: \"GDP(in Billions of chained 2009)\"}, \n",
    "                        inplace=True\n",
    "              )\n",
    "indexFor2000Start = GDP_qtr[GDP_qtr['YearQuarters'] == '2000q1'].index.item()\n",
    "indexFor2000Start\n",
    "\n",
    "GDP_qtr = GDP_qtr.loc[indexFor2000Start:]\n",
    "#GDP_qtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008q3'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recession_start():\n",
    "    '''Returns the year and quarter of the recession start time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    \n",
    "\n",
    "#  A recession is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "#(use the chained value in 2009 dollars)  \n",
    "#     For this assignment, only look at GDP data from the first quarter of 2000 onward.\n",
    "    for i, row in GDP_qtr.iterrows():\n",
    "\n",
    "        if (GDP_qtr.loc[i+2, 'GDP(in Billions of chained 2009)'] < GDP_qtr.loc[i+1, 'GDP(in Billions of chained 2009)']) & (GDP_qtr.loc[i+1, 'GDP(in Billions of chained 2009)'] < GDP_qtr.loc[i, 'GDP(in Billions of chained 2009)']):\n",
    "            return GDP_qtr.loc[i+1, 'YearQuarters']\n",
    "        \n",
    "    return \"No recession\"\n",
    "\n",
    "get_recession_start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009q3'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recession_end():\n",
    "    '''Returns the year and quarter of the recession end time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    \n",
    "    \n",
    "    recessionStart = get_recession_start()\n",
    "    startIter = GDP_qtr[GDP_qtr['YearQuarters']==recessionStart].index.item()\n",
    "\n",
    "    #Find the index of the start of the recession and start iterating from that onwards to check rise of GDP\n",
    "    for i, row in GDP_qtr.iterrows():\n",
    "        if i < startIter:\n",
    "            continue\n",
    "        else:\n",
    "            if (GDP_qtr.loc[i+2, 'GDP(in Billions of chained 2009)'] > GDP_qtr.loc[i+1, 'GDP(in Billions of chained 2009)']) & (GDP_qtr.loc[i+1, 'GDP(in Billions of chained 2009)'] > GDP_qtr.loc[i, 'GDP(in Billions of chained 2009)']):\n",
    "                return GDP_qtr.loc[i+1, 'YearQuarters']\n",
    "\n",
    "    return \"No recession end\"\n",
    "    \n",
    "# get_recession_end()\n",
    "\n",
    "#('2008q3', '2009q3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009Q2'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recession_bottom():\n",
    "    '''Returns the year and quarter of the recession bottom time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    \n",
    "    #     A recession bottom is the quarter within a recession which had the lowest GDP.\n",
    "    recessionStart = get_recession_start()\n",
    "    recessionEnd = get_recession_end()\n",
    "    \n",
    "    startIter = GDP_qtr[GDP_qtr['YearQuarters']==recessionStart].index.item()\n",
    "    endIter = GDP_qtr[GDP_qtr['YearQuarters']==recessionEnd].index.item()\n",
    "    \n",
    "   \n",
    "    GDP_recession = GDP_qtr.loc[startIter:endIter, 'GDP(in Billions of chained 2009)'].min() #14355.6\n",
    "    GDP_recession_idx = GDP_qtr.loc[startIter:endIter, 'GDP(in Billions of chained 2009)'].idxmin()\n",
    "    \n",
    "    return GDP_qtr.loc[GDP_recession_idx]['YearQuarters'].upper()\n",
    "\n",
    "get_recession_bottom()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2000Q1</th>\n",
       "      <th>2000Q2</th>\n",
       "      <th>2000Q3</th>\n",
       "      <th>2000Q4</th>\n",
       "      <th>2001Q1</th>\n",
       "      <th>2001Q2</th>\n",
       "      <th>2001Q3</th>\n",
       "      <th>2001Q4</th>\n",
       "      <th>2002Q1</th>\n",
       "      <th>2002Q2</th>\n",
       "      <th>...</th>\n",
       "      <th>2014Q2</th>\n",
       "      <th>2014Q3</th>\n",
       "      <th>2014Q4</th>\n",
       "      <th>2015Q1</th>\n",
       "      <th>2015Q2</th>\n",
       "      <th>2015Q3</th>\n",
       "      <th>2015Q4</th>\n",
       "      <th>2016Q1</th>\n",
       "      <th>2016Q2</th>\n",
       "      <th>2016Q3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <th>New York</th>\n",
       "      <td>243464.000000</td>\n",
       "      <td>252251.666667</td>\n",
       "      <td>260138.666667</td>\n",
       "      <td>268484.000000</td>\n",
       "      <td>277120.333333</td>\n",
       "      <td>286576.666667</td>\n",
       "      <td>293365.333333</td>\n",
       "      <td>300368.000000</td>\n",
       "      <td>307615.333333</td>\n",
       "      <td>307932.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>492571.000000</td>\n",
       "      <td>499305.333333</td>\n",
       "      <td>506530.666667</td>\n",
       "      <td>513433.666667</td>\n",
       "      <td>522421.333333</td>\n",
       "      <td>533102.000000</td>\n",
       "      <td>542734.333333</td>\n",
       "      <td>551434.666667</td>\n",
       "      <td>560075.666667</td>\n",
       "      <td>567197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>236294.666667</td>\n",
       "      <td>242379.333333</td>\n",
       "      <td>248779.333333</td>\n",
       "      <td>255336.333333</td>\n",
       "      <td>261622.000000</td>\n",
       "      <td>268508.666667</td>\n",
       "      <td>274942.000000</td>\n",
       "      <td>282457.000000</td>\n",
       "      <td>291412.666667</td>\n",
       "      <td>302555.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>530952.333333</td>\n",
       "      <td>534494.000000</td>\n",
       "      <td>537976.000000</td>\n",
       "      <td>550407.000000</td>\n",
       "      <td>559531.333333</td>\n",
       "      <td>567509.666667</td>\n",
       "      <td>579534.000000</td>\n",
       "      <td>591045.000000</td>\n",
       "      <td>604423.000000</td>\n",
       "      <td>613363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <th>Houston</th>\n",
       "      <td>106242.666667</td>\n",
       "      <td>106365.666667</td>\n",
       "      <td>107054.000000</td>\n",
       "      <td>108204.666667</td>\n",
       "      <td>108867.333333</td>\n",
       "      <td>108614.000000</td>\n",
       "      <td>108833.000000</td>\n",
       "      <td>109410.333333</td>\n",
       "      <td>110188.000000</td>\n",
       "      <td>111795.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>140745.666667</td>\n",
       "      <td>145022.000000</td>\n",
       "      <td>149337.333333</td>\n",
       "      <td>152946.333333</td>\n",
       "      <td>156465.000000</td>\n",
       "      <td>158326.666667</td>\n",
       "      <td>160039.000000</td>\n",
       "      <td>162204.000000</td>\n",
       "      <td>163464.333333</td>\n",
       "      <td>165267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <th>Chicago</th>\n",
       "      <td>157851.000000</td>\n",
       "      <td>162824.333333</td>\n",
       "      <td>167271.666667</td>\n",
       "      <td>171826.333333</td>\n",
       "      <td>176428.333333</td>\n",
       "      <td>181054.666667</td>\n",
       "      <td>185542.000000</td>\n",
       "      <td>190079.666667</td>\n",
       "      <td>194006.666667</td>\n",
       "      <td>197951.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>199324.666667</td>\n",
       "      <td>202455.333333</td>\n",
       "      <td>205087.333333</td>\n",
       "      <td>206689.666667</td>\n",
       "      <td>209998.666667</td>\n",
       "      <td>212235.333333</td>\n",
       "      <td>213732.000000</td>\n",
       "      <td>217486.000000</td>\n",
       "      <td>220779.666667</td>\n",
       "      <td>223351.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <th>San Antonio</th>\n",
       "      <td>102291.000000</td>\n",
       "      <td>101794.333333</td>\n",
       "      <td>100507.666667</td>\n",
       "      <td>100411.666667</td>\n",
       "      <td>100022.000000</td>\n",
       "      <td>99548.333333</td>\n",
       "      <td>99589.666667</td>\n",
       "      <td>99274.666667</td>\n",
       "      <td>99337.333333</td>\n",
       "      <td>100250.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>134430.666667</td>\n",
       "      <td>136107.333333</td>\n",
       "      <td>138042.333333</td>\n",
       "      <td>140489.666667</td>\n",
       "      <td>142810.000000</td>\n",
       "      <td>145803.666667</td>\n",
       "      <td>148585.333333</td>\n",
       "      <td>150489.000000</td>\n",
       "      <td>153440.333333</td>\n",
       "      <td>155199.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <th>Winton</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>80003.000000</td>\n",
       "      <td>81083.666667</td>\n",
       "      <td>80732.000000</td>\n",
       "      <td>83166.333333</td>\n",
       "      <td>85120.666667</td>\n",
       "      <td>87088.333333</td>\n",
       "      <td>87195.333333</td>\n",
       "      <td>83964.333333</td>\n",
       "      <td>82354.666667</td>\n",
       "      <td>79129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <th>Eastabuchie</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>63276.000000</td>\n",
       "      <td>63448.333333</td>\n",
       "      <td>64417.666667</td>\n",
       "      <td>66019.333333</td>\n",
       "      <td>66523.333333</td>\n",
       "      <td>66922.000000</td>\n",
       "      <td>66960.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>66313.333333</td>\n",
       "      <td>65820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <th>Dean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>132332.666667</td>\n",
       "      <td>133835.333333</td>\n",
       "      <td>136007.000000</td>\n",
       "      <td>137525.000000</td>\n",
       "      <td>138844.333333</td>\n",
       "      <td>141260.666667</td>\n",
       "      <td>141728.333333</td>\n",
       "      <td>143110.333333</td>\n",
       "      <td>145840.666667</td>\n",
       "      <td>148203.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <th>Pulaski</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>67048.000000</td>\n",
       "      <td>68462.333333</td>\n",
       "      <td>70082.666667</td>\n",
       "      <td>71652.333333</td>\n",
       "      <td>73485.000000</td>\n",
       "      <td>74925.666667</td>\n",
       "      <td>76344.000000</td>\n",
       "      <td>79169.000000</td>\n",
       "      <td>81018.000000</td>\n",
       "      <td>82508.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <th>New Paris</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>70134.333333</td>\n",
       "      <td>72293.333333</td>\n",
       "      <td>72727.666667</td>\n",
       "      <td>72679.333333</td>\n",
       "      <td>71555.666667</td>\n",
       "      <td>71450.333333</td>\n",
       "      <td>72224.333333</td>\n",
       "      <td>72844.333333</td>\n",
       "      <td>73690.000000</td>\n",
       "      <td>73612.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27330 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 2000Q1         2000Q2         2000Q3  \\\n",
       "State        RegionName                                                 \n",
       "New York     New York     243464.000000  252251.666667  260138.666667   \n",
       "California   Los Angeles  236294.666667  242379.333333  248779.333333   \n",
       "Texas        Houston      106242.666667  106365.666667  107054.000000   \n",
       "Illinois     Chicago      157851.000000  162824.333333  167271.666667   \n",
       "Texas        San Antonio  102291.000000  101794.333333  100507.666667   \n",
       "...                                 ...            ...            ...   \n",
       "Minnesota    Winton                 NaN            NaN            NaN   \n",
       "Mississippi  Eastabuchie            NaN            NaN            NaN   \n",
       "Texas        Dean                   NaN            NaN            NaN   \n",
       "Georgia      Pulaski                NaN            NaN            NaN   \n",
       "Pennsylvania New Paris              NaN            NaN            NaN   \n",
       "\n",
       "                                 2000Q4         2001Q1         2001Q2  \\\n",
       "State        RegionName                                                 \n",
       "New York     New York     268484.000000  277120.333333  286576.666667   \n",
       "California   Los Angeles  255336.333333  261622.000000  268508.666667   \n",
       "Texas        Houston      108204.666667  108867.333333  108614.000000   \n",
       "Illinois     Chicago      171826.333333  176428.333333  181054.666667   \n",
       "Texas        San Antonio  100411.666667  100022.000000   99548.333333   \n",
       "...                                 ...            ...            ...   \n",
       "Minnesota    Winton                 NaN            NaN            NaN   \n",
       "Mississippi  Eastabuchie            NaN            NaN            NaN   \n",
       "Texas        Dean                   NaN            NaN            NaN   \n",
       "Georgia      Pulaski                NaN            NaN            NaN   \n",
       "Pennsylvania New Paris              NaN            NaN            NaN   \n",
       "\n",
       "                                 2001Q3         2001Q4         2002Q1  \\\n",
       "State        RegionName                                                 \n",
       "New York     New York     293365.333333  300368.000000  307615.333333   \n",
       "California   Los Angeles  274942.000000  282457.000000  291412.666667   \n",
       "Texas        Houston      108833.000000  109410.333333  110188.000000   \n",
       "Illinois     Chicago      185542.000000  190079.666667  194006.666667   \n",
       "Texas        San Antonio   99589.666667   99274.666667   99337.333333   \n",
       "...                                 ...            ...            ...   \n",
       "Minnesota    Winton                 NaN            NaN            NaN   \n",
       "Mississippi  Eastabuchie            NaN            NaN            NaN   \n",
       "Texas        Dean                   NaN            NaN            NaN   \n",
       "Georgia      Pulaski                NaN            NaN            NaN   \n",
       "Pennsylvania New Paris              NaN            NaN            NaN   \n",
       "\n",
       "                                 2002Q2  ...         2014Q2         2014Q3  \\\n",
       "State        RegionName                  ...                                 \n",
       "New York     New York     307932.666667  ...  492571.000000  499305.333333   \n",
       "California   Los Angeles  302555.333333  ...  530952.333333  534494.000000   \n",
       "Texas        Houston      111795.333333  ...  140745.666667  145022.000000   \n",
       "Illinois     Chicago      197951.000000  ...  199324.666667  202455.333333   \n",
       "Texas        San Antonio  100250.000000  ...  134430.666667  136107.333333   \n",
       "...                                 ...  ...            ...            ...   \n",
       "Minnesota    Winton                 NaN  ...   80003.000000   81083.666667   \n",
       "Mississippi  Eastabuchie            NaN  ...   63276.000000   63448.333333   \n",
       "Texas        Dean                   NaN  ...  132332.666667  133835.333333   \n",
       "Georgia      Pulaski                NaN  ...   67048.000000   68462.333333   \n",
       "Pennsylvania New Paris              NaN  ...   70134.333333   72293.333333   \n",
       "\n",
       "                                 2014Q4         2015Q1         2015Q2  \\\n",
       "State        RegionName                                                 \n",
       "New York     New York     506530.666667  513433.666667  522421.333333   \n",
       "California   Los Angeles  537976.000000  550407.000000  559531.333333   \n",
       "Texas        Houston      149337.333333  152946.333333  156465.000000   \n",
       "Illinois     Chicago      205087.333333  206689.666667  209998.666667   \n",
       "Texas        San Antonio  138042.333333  140489.666667  142810.000000   \n",
       "...                                 ...            ...            ...   \n",
       "Minnesota    Winton        80732.000000   83166.333333   85120.666667   \n",
       "Mississippi  Eastabuchie   64417.666667   66019.333333   66523.333333   \n",
       "Texas        Dean         136007.000000  137525.000000  138844.333333   \n",
       "Georgia      Pulaski       70082.666667   71652.333333   73485.000000   \n",
       "Pennsylvania New Paris     72727.666667   72679.333333   71555.666667   \n",
       "\n",
       "                                 2015Q3         2015Q4         2016Q1  \\\n",
       "State        RegionName                                                 \n",
       "New York     New York     533102.000000  542734.333333  551434.666667   \n",
       "California   Los Angeles  567509.666667  579534.000000  591045.000000   \n",
       "Texas        Houston      158326.666667  160039.000000  162204.000000   \n",
       "Illinois     Chicago      212235.333333  213732.000000  217486.000000   \n",
       "Texas        San Antonio  145803.666667  148585.333333  150489.000000   \n",
       "...                                 ...            ...            ...   \n",
       "Minnesota    Winton        87088.333333   87195.333333   83964.333333   \n",
       "Mississippi  Eastabuchie   66922.000000   66960.000000   66296.000000   \n",
       "Texas        Dean         141260.666667  141728.333333  143110.333333   \n",
       "Georgia      Pulaski       74925.666667   76344.000000   79169.000000   \n",
       "Pennsylvania New Paris     71450.333333   72224.333333   72844.333333   \n",
       "\n",
       "                                 2016Q2    2016Q3  \n",
       "State        RegionName                            \n",
       "New York     New York     560075.666667  567197.0  \n",
       "California   Los Angeles  604423.000000  613363.0  \n",
       "Texas        Houston      163464.333333  165267.0  \n",
       "Illinois     Chicago      220779.666667  223351.5  \n",
       "Texas        San Antonio  153440.333333  155199.5  \n",
       "...                                 ...       ...  \n",
       "Minnesota    Winton        82354.666667   79129.0  \n",
       "Mississippi  Eastabuchie   66313.333333   65820.0  \n",
       "Texas        Dean         145840.666667  148203.5  \n",
       "Georgia      Pulaski       81018.000000   82508.5  \n",
       "Pennsylvania New Paris     73690.000000   73612.5  \n",
       "\n",
       "[27330 rows x 67 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_housing_data_to_quarters():\n",
    "    '''Converts the housing data to quarters and returns it as mean \n",
    "    values in a dataframe. This dataframe should be a dataframe with\n",
    "    columns for 2000q1 through 2016q3, and should have a multi-index\n",
    "    in the shape of [\"State\",\"RegionName\"].\n",
    "    \n",
    "    Note: Quarters are defined in the assignment description, they are\n",
    "    not arbitrary three month periods.\n",
    "    \n",
    "    The resulting dataframe should have 67 columns, and 10,730 rows.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    zillow_allhomes_df  = pd.read_csv(r'C:\\Users\\sjtal\\Documents\\python_datascience\\City_Zhvi_AllHomes.csv')\n",
    "    zillow_allhomes_df.loc[:, 'State'] = zillow_allhomes_df.loc[:, 'State'].map(states)\n",
    "    temp_zillow = zillow_allhomes_df.copy()\n",
    "\n",
    "    temp_zillow.set_index([\"State\",\"RegionName\"], inplace=True)\n",
    "\n",
    "    #  convert column  names to datetime\n",
    "    temp_zillow = temp_zillow[temp_zillow.columns[6:]].rename(columns=pd.to_datetime)\n",
    "\n",
    "    columns_we_need  = temp_zillow.columns\n",
    "    columns_we_need = columns_we_need[(columns_we_need > '1999-12-31') & (columns_we_need < '2016-09-01')]\n",
    "\n",
    "    temp_zillow = temp_zillow[columns_we_need].resample('QS',axis=1).mean()\n",
    "\n",
    "\n",
    "    #Convert dates to Quarter periods\n",
    "    month_names = temp_zillow.columns\n",
    "    month_names = pd.PeriodIndex(month_names, freq='Q')\n",
    "\n",
    "    #Assign Quater names as column names\n",
    "    temp_zillow.columns = month_names\n",
    "    \n",
    "    #Makes ure the data in the periodindex columns are converted to str so that Merge and Join do not throw an error  \n",
    "    temp_zillow.columns.values.astype('str')\n",
    "   \n",
    "    zillow_allhomes_df = temp_zillow\n",
    "  \n",
    "    zillow_allhomes_df = zillow_allhomes_df.reset_index()\n",
    "    zillow_allhomes_df.set_index(['State', 'RegionName'], inplace=True, drop = True)\n",
    "    \n",
    "    return zillow_allhomes_df\n",
    "\n",
    "\n",
    "#convert_housing_data_to_quarters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-04-01 00:00:00')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For calendar with 2018 quarter starting in April 2017\n",
    "per = pd.Period('2018Q1', freq='Q-MAR')\n",
    "per.start_time\n",
    "#Timestamp('2017-04-01 00:00:00')\n",
    "# per.qyear\n",
    "# #2018\n",
    "# per.year\n",
    "#2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MarkUniv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n",
       "      <th>Auburn</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florence</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jacksonville</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Livingston</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montevallo</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Wisconsin</th>\n",
       "      <th>River Falls</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stevens Point</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waukesha</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whitewater</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <th>Laramie</th>\n",
       "      <td>UnivTown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MarkUniv\n",
       "State     RegionName             \n",
       "Alabama   Auburn         UnivTown\n",
       "          Florence       UnivTown\n",
       "          Jacksonville   UnivTown\n",
       "          Livingston     UnivTown\n",
       "          Montevallo     UnivTown\n",
       "...                           ...\n",
       "Wisconsin River Falls    UnivTown\n",
       "          Stevens Point  UnivTown\n",
       "          Waukesha       UnivTown\n",
       "          Whitewater     UnivTown\n",
       "Wyoming   Laramie        UnivTown\n",
       "\n",
       "[513 rows x 1 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# univ_towns = get_list_of_university_towns().assign(MarkUniv='UnivTown').set_index([\"State\", \"RegionName\"]).sort_index(inplace=True)\n",
    "univ_towns = (get_list_of_university_towns().assign(MarkUniv='UnivTown')\n",
    "              .set_index([\"State\", \"RegionName\"])\n",
    "             )\n",
    "\n",
    "univ_towns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis: University towns have their mean housing prices less effected by recessions. Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom. (price_ratio=quarter_before_recession/recession_bottom)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter before recession start : 2008Q2\n",
      "T test result :  Ttest_indResult(statistic=0.10935039821678649, pvalue=0.9129255377091339)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('No', 0.9129255377091339, 'Non-university town')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def run_ttest():\n",
    "    \"\"\"First creates new data showing the decline or growth of housing prices\n",
    "    between the recession start and the recession bottom. Then runs a ttest\n",
    "    comparing the university town values to the non-university towns values, \n",
    "    return whether the alternative hypothesis (that the two groups are the same)\n",
    "    is t ()rue or not as well as the p-value of the confidence. \n",
    "    \n",
    "    Return the tuple (different, p, better) where different=True if the t-test is\n",
    "    True at a p<0.01 (we reject the null hypothesis), or different=False if \n",
    "    otherwise (we cannot reject the null hypothesis). The variable p should\n",
    "    be equal to the exact p value returned from scipy.stats.ttest_ind(). The\n",
    "    value for better should be either \"university town\" or \"non-university town\"\n",
    "    depending on which has a lower mean price ratio (which is equivilent to a\n",
    "    reduced market loss).\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    univ_towns = (get_list_of_university_towns()\n",
    "                  .assign(MarkUniv='UnivTown')\n",
    "                  .set_index([\"State\", \"RegionName\"])\n",
    "                 )\n",
    "    univ_towns.sort_index(inplace=True)\n",
    "    univ_towns.replace(value=\"Seattle\", to_replace=\"University District\", inplace=True)\n",
    "\n",
    "    housing_data = convert_housing_data_to_quarters()\n",
    "    housing_data.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    univ_towns_housing = pd.merge(housing_data, univ_towns, how=\"left\", left_index=True, right_index=True)\n",
    "    univ_towns_housing.columns = univ_towns_housing.columns.astype('str')\n",
    "    \n",
    "\n",
    "    rec_start = get_recession_start().upper()\n",
    "    rec_bottom = get_recession_bottom().upper()\n",
    "\n",
    "    rec_start_previous = univ_towns_housing.columns.get_loc(rec_start) - 1\n",
    "    qtr_before_rec_start =univ_towns_housing.columns[rec_start_previous]\n",
    "    print(\"Quarter before recession start :\", qtr_before_rec_start)\n",
    "    \n",
    "    univ_towns_housing['Ratio']=univ_towns_housing.apply(lambda x: x[qtr_before_rec_start]/x[rec_bottom],axis=1)\n",
    "\n",
    "    \n",
    "    non_univ_towns_housing = univ_towns_housing[univ_towns_housing['MarkUniv'].isnull()]\n",
    "    univ_towns_housing = univ_towns_housing[univ_towns_housing['MarkUniv'] == 'UnivTown']\n",
    "\n",
    "    tTestResult = ttest_ind(univ_towns_housing.loc[:,'Ratio'].dropna(), non_univ_towns_housing.loc[:,'Ratio'].dropna())\n",
    "\n",
    "    testStatistic = tTestResult [0] \n",
    "    pValue = tTestResult [1] \n",
    "    print(\"T test result : \"  , tTestResult)\n",
    "    \n",
    "    university_mean = univ_towns_housing['Ratio'].mean()\n",
    "    nonuniversity_mean = non_univ_towns_housing['Ratio'].mean()\n",
    "    \n",
    "    better = 'university town' if university_mean < nonuniversity_mean else 'Non-university town'\n",
    "    different = 'Yes' if pValue < 0.01 else 'No'\n",
    "\n",
    "    return (different,pValue,better)\n",
    "\n",
    "# #Ttest_indResult(statistic=-2.9195072956955008, pvalue=0.0035137908912504863)\n",
    "run_ttest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
